---
layout: about
title: About
permalink: /
subtitle: >
  <p>Incoming Assistant Professor <a href="https://mbzuai.ac.ae/">@MBZUAI</a></p>
  <p>nils.lukas@mbzuai.ac.ae</p>

profile:
  align: right
  image: nils-profile.jpg
  image_circular: false # crops the image to make it circular
  address: >
    <p>Toronto, Canada</p>

news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

Guten Tag :wave: ,
I am an incoming Assistant Professor at <a href="https://mbzuai.ac.ae/">MBZUAI</a> in Abu Dhabi, beginning August 2024.
Previously, I did my PhD at the University of Waterloo in Canada, where I was supervised by <a href="https://cs.uwaterloo.ca/~fkerschb/">Florian Kerschbaum</a>. 
During my PhD I interned at <a href="https://www.microsoft.com/en-us/research/group/privacy-preserving-machine-learning-innovation/publications/">Microsoft Research</a> and <a href="https://www.borealisai.com/">Borealis AI</a> and I was supported by the David R. Cheriton scholarship.
In 2024, I received the <a href="https://cs.uwaterloo.ca/news/nils-lukas-receives-2024-mathematics-doctoral-prizes-top-honour">Mathematics Doctoral Prize’s</a> at the University of Waterloo and 
was nominated for the <a href="https://uwaterloo.ca/graduate-studies-postdoctoral-affairs/governor-generals-gold-medal-winners">Governor General’s Gold Medal</a>. 
<br>
<div style="text-align: center;">
<a href="https://nilslukas.github.io/assets/pdf/cv_nils_lukas.pdf">[Curriculum Vitae]</a>, <a href="https://nilslukas.github.io/assets/pdf/research_statement.pdf">[Research Statement]</a>
</div>
<br>

<b style="color: red;">Please reach out to me via e-mail if you are interested in joining MBZUAI. 
You can find admission details <a href="https://mbzuai.ac.ae/study/admission-process/">here</a>.</b>


My research focuses on designing safe and reliable Machine Learning systems in the presence of untrustworthy
1. <b>Providers:</b> Confidential computing via Homomorphic Encryption & Secret Sharing.
2. <b>Data:</b> Mitigate data poisoning during training & prompt injection during inference.
3. <b>Models:</b> Protect training data privacy through PII scrubbing & differential privacy.
4. <b>Users:</b> Control misuse by detecting generated (mis)information with watermarking

My work includes studying privacy attacks against large language models fine-tuned on private datasets, developing defenses against data poisoning, and creating multiple methods for controlling model misuse. In collaboration with our group, I have also contributed to developing Secure Multi-Party Computation protocols for Private Information Retrieval and the Secure Inference of Deep Neural Networks.
I received a Master of Science from the <a href="https://www.rwth-aachen.de/go/id/a/?lidx=1">RWTH-Aachen</a> (Germany) in 2019.

If you have any questions or would like to learn more about my work, please feel free to contact me. You can also find my work on <a href="https://github.com/nilslukas/">GitHub</a>.
